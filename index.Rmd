---
title: 'Project 2: Data Mining, Classification, Prediction'
author: "SDS322E"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))

class_diag <- function(score, truth, positive, cutoff=.5){

  pred <- factor(score>cutoff,levels=c("TRUE","FALSE"))
  truth <- factor(truth==positive, levels=c("TRUE","FALSE"))

  tab<-table(truth, pred)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[1,1]/rowSums(tab)[1]
  spec=tab[2,2]/rowSums(tab)[2]
  ppv=tab[1,1]/colSums(tab)[1]

#CALCULATE F1
  f1=2*(sens*ppv)/(sens+ppv)
  
#CALCULATE EXACT AUC
  truth<-as.numeric(truth=="TRUE")
  ord<-order(score, decreasing=TRUE)
  score <- score[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(score[-1]>=score[-length(score)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  round(data.frame(acc,sens,spec,ppv,f1,ba=(sens+spec)/2,auc, row.names = "Metrics"),4)
}
```

# Mining, Classification, Prediction

## Elicenda Tovar (et22536)

### Introduction 

Paragraph or two introducing your datasets and variables, why they are interesting to you, etc. See instructions for more information. HELPmiss:	Health Evaluation and Linkage to Primary Care. Datasets 1-4 were used in project one. All of the data was obtained from the Texas county health ranking website. The new data includes the proportion of adult individuals that are considered obese in each of the Texas counties in 2017 and the proportion of the population who are low-income and do not live close to a grocery store in 2015.  

```{R}
library(tidyverse)
data1 <- read.csv("~/uninsured.csv")
data2 <- read.csv("~/unemployment.csv")
data3 <- read.csv("~/pmhd.csv") #poor mental health days
data4 <- read.csv("~/pphd.csv") #poor physical health days
data5 <- read.csv("~/obesity.csv") #proportion of obese individuals in each county
data6 <- read.csv("~/LAHF.csv") #proportion of individuals in each county with limited access to healthy foods.

# cleaning the detasets 
data1<- subset(data1, select=c(County,X..Uninsured)) 
data1<- rename(data1, Uninsured=X..Uninsured)
count1<-data1 %>% group_by(County) %>% summarise(n())

data2<- subset(data2, select=c(County,X..Unemployed, Labor.Force))
data2<-rename(data2, Unemployed=X..Unemployed)
count2<-data2 %>% group_by(County) %>% summarise(n())

data3<- subset(data3, select=c(County,County.Value.))
data3<-rename(data3, PoorMHdays=County.Value.)
cunt3<-data3 %>% group_by(County) %>% summarise(n())

data4<- subset(data4, select=c(County,County.Value.))
data4<-rename(data4, PoorPHdays=County.Value.)
count4<-data4 %>% group_by(County) %>% summarise(n())

unique<-union(data1$County, data2$County)
unique2<-union(data3$County, data4$County)

# joining code below 
full<- full_join(data1, data2, by=c("County"))
full2<- full_join(full, data3, by=c("County"))
full3<- full_join(full2, data4, by=c("County"))
full4<- full_join(full3, data5, by=c("County"))
full5<- full_join(full4, data6, by=c("County"))

# if your dataset needs tidying, do so here

# any other code here
```

### Cluster Analysis

```{R}
library(cluster)
# clustering code here
```

Discussion of clustering here
    
    
### Dimensionality Reduction with PCA

```{R}
# PCA code here
```

Discussions of PCA here. 

###  Linear Classifier

```{R}
# linear classifier code here
```

```{R}
# cross-validation of linear classifier here
```

Discussion here

### Non-Parametric Classifier

```{R}
library(caret)
# non-parametric classifier code here
```

```{R}
# cross-validation of np classifier here
```

Discussion


### Regression/Numeric Prediction

```{R}
# regression model code here
```

```{R}
# cross-validation of regression model here
```

Discussion

### Python 

```{R}
library(reticulate)
```

```{python}
# python code here
```

Discussion

### Concluding Remarks

Include concluding remarks here, if any




